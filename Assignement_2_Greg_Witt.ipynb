{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b133c7d-94cd-4d88-ad3b-ec756ed6c369",
   "metadata": {},
   "source": [
    "# Assignment 2: Large Language Models for Text Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8088e649-206e-4c4f-a802-ef860fc873f1",
   "metadata": {},
   "source": [
    "### CS 410/510 Large Language Models Fall 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995529cd-a516-45b5-ab5c-a76d668871d8",
   "metadata": {},
   "source": [
    "#### Greg Witt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b870bd-7be3-4447-b531-77dbaafec5f1",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2eaa395-0356-4d84-bd75-7c632ede4141",
   "metadata": {},
   "source": [
    "**Install Dependencies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "101775ae-ee6b-419e-ba63-291fe04b99c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "85077.27s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in ./.venv/lib/python3.12/site-packages (3.0.2)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.12/site-packages (from datasets) (3.16.1)\n",
      "Requirement already satisfied: numpy>=1.17 in ./.venv/lib/python3.12/site-packages (from datasets) (2.1.2)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in ./.venv/lib/python3.12/site-packages (from datasets) (18.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in ./.venv/lib/python3.12/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in ./.venv/lib/python3.12/site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in ./.venv/lib/python3.12/site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in ./.venv/lib/python3.12/site-packages (from datasets) (4.66.6)\n",
      "Requirement already satisfied: xxhash in ./.venv/lib/python3.12/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in ./.venv/lib/python3.12/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in ./.venv/lib/python3.12/site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
      "Requirement already satisfied: aiohttp in ./.venv/lib/python3.12/site-packages (from datasets) (3.10.10)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in ./.venv/lib/python3.12/site-packages (from datasets) (0.26.2)\n",
      "Requirement already satisfied: packaging in ./.venv/lib/python3.12/site-packages (from datasets) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./.venv/lib/python3.12/site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in ./.venv/lib/python3.12/site-packages (from aiohttp->datasets) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./.venv/lib/python3.12/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.venv/lib/python3.12/site-packages (from aiohttp->datasets) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.venv/lib/python3.12/site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.venv/lib/python3.12/site-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in ./.venv/lib/python3.12/site-packages (from aiohttp->datasets) (1.17.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.venv/lib/python3.12/site-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.12/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.12/site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.12/site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./.venv/lib/python3.12/site-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets) (0.2.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30dfd64a-475d-4daf-8546-7ebcd287e6e6",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6dc5a88f-c340-4bb8-a21c-d0c68f57ac8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tweet_sentiment_multilingual training dataset: \n",
      "    -----------------------------------------\n",
      "        Dataset({\n",
      "    features: ['text', 'label'],\n",
      "    num_rows: 1839\n",
      "}) \n",
      "    \n",
      "\n",
      "    Random Tweet:\n",
      "    @user went to get vip for February 11th show and you're sold out my heart is broken I can't meet you with my big brother \n",
      "\n",
      "    Label: \n",
      "    0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import random\n",
    "\n",
    "# load the training set of tweets\n",
    "ds_train = load_dataset(\"cardiffnlp/tweet_sentiment_multilingual\", \"english\", split=\"train\")\n",
    "# the dataset labels {0 : negative, 1: neutral, 2: positive }\n",
    "print(f\"\"\"tweet_sentiment_multilingual training dataset: \n",
    "    -----------------------------------------\n",
    "        {ds_train} \n",
    "    \"\"\")\n",
    "random_tweet_index = random.randint(0,1839)\n",
    "print(f\"\"\"\n",
    "    Random Tweet:\n",
    "    {ds_train['text'][random_tweet_index]}\n",
    "\n",
    "    Label: \n",
    "    {ds_train['label'][random_tweet_index] }\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50bf010e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tweet_sentiment_multilingual validation set: \n",
      "    -----------------------------------------\n",
      "        Dataset({\n",
      "    features: ['text', 'label'],\n",
      "    num_rows: 324\n",
      "})\n",
      "    \n",
      "\n",
      "    Random Tweet:\n",
      "    @user digi was on the 18th but i didn't go but im going to slaybells \n",
      "\n",
      "    Label: \n",
      "    2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# load the training set of tweets\n",
    "ds_validation = load_dataset(\"cardiffnlp/tweet_sentiment_multilingual\", \"english\", split=\"validation\")\n",
    "# the dataset labels {0 : negative, 1: neutral, 2: positive }\n",
    "print(f\"\"\"tweet_sentiment_multilingual validation set: \n",
    "    -----------------------------------------\n",
    "        {ds_validation}\n",
    "    \"\"\")\n",
    "random_tweet_index = random.randint(0,324)\n",
    "print(f\"\"\"\n",
    "    Random Tweet:\n",
    "    {ds_validation['text'][random_tweet_index]}\n",
    "\n",
    "    Label: \n",
    "    {ds_validation['label'][random_tweet_index] }\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65fbc96",
   "metadata": {},
   "source": [
    "## Load the Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3310abc7",
   "metadata": {},
   "source": [
    "**Load Dependencies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69fc74e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ebbb03f",
   "metadata": {},
   "source": [
    "#### [Lama 3.2 1B](https://huggingface.co/meta-llama/Llama-3.2-1B) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0c87e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "llama_3_2_1B = \"meta-llama/Llama-3.2-1B\"\n",
    "\n",
    "llama_3_2_1B_tokenizer = AutoTokenizer.from_pretrained(llama_3_2_1B)\n",
    "\n",
    "llama_3_2_1B_model = AutoModelForCausalLM.from_pretrained(llama_3_2_1B)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b02fd010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer assigns the probability \n",
    "\"Text: I hate it! \\nSentiment (positive, negative, neutral):\"\n",
    "\n",
    "prompt_approach_two = f\"\"\"{tweet} Sentiment: \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c076a312",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYour text to classify here.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Tokenize the text\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m inputs \u001b[38;5;241m=\u001b[39m \u001b[43mtokenizer\u001b[49m(text, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Get model predictions\u001b[39;00m\n\u001b[1;32m      8\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "# Text to classify\n",
    "text = \"Your text to classify here.\"\n",
    "\n",
    "# Tokenize the text\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "\n",
    "# Get model predictions\n",
    "outputs = model(**inputs)\n",
    "logits = outputs.logits\n",
    "\n",
    "# Determine the predicted class\n",
    "predicted_class = torch.argmax(logits, dim=1).item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debb8de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(**inputs, labels=inputs[\"input_ids\"])\n",
    "    log_probs = torch.nn.functional.log_softmax(outputs.logits, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ae1260ea",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Experiment' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mExperiment\u001b[49m \u001b[38;5;66;03m#2 \u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Experiment' is not defined"
     ]
    }
   ],
   "source": [
    "Experiment #2 \n",
    "\n",
    "1 prompt  2 positive , 2 negative, 2 neutral k = 2 {tweet} : Sentiment {?} =>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "363c01b4",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "expected 'else' after 'if' expression (2972846960.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[23], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    google_this if needed.\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m expected 'else' after 'if' expression\n"
     ]
    }
   ],
   "source": [
    "# 3 \n",
    "google_this if needed.\n",
    "chain_of_thought = \"think about this step by step this sound positive, negative, neurtal?\\n\"\n",
    "f\"{chain_of_thought} {tweet}\"\n",
    "\n",
    "# emotion based: pull on compassion strings.\n",
    "\"I need this for my job: classify as negative, positive or neutral\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eccdae2",
   "metadata": {},
   "source": [
    "#### [Phi 3.5 Instruct]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7003448",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a01870a9",
   "metadata": {},
   "source": [
    "**Load The Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ff264a6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a50af457bc64d7c9f303b251e7e2e31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[101], line 9\u001b[0m\n\u001b[1;32m      5\u001b[0m phi_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmicrosoft/Phi-3.5-mini-instruct\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      7\u001b[0m phi_3_5_tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(phi_model)\n\u001b[0;32m----> 9\u001b[0m phi_3_5_model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mphi_model\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Large-Language-Models/Assignments/LLM-PSU-Assignment-2/.venv/lib/python3.12/site-packages/transformers/models/auto/auto_factory.py:564\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    563\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[0;32m--> 564\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    565\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    566\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    567\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    568\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    569\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    570\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/Large-Language-Models/Assignments/LLM-PSU-Assignment-2/.venv/lib/python3.12/site-packages/transformers/modeling_utils.py:4225\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   4215\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype_orig \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   4216\u001b[0m         torch\u001b[38;5;241m.\u001b[39mset_default_dtype(dtype_orig)\n\u001b[1;32m   4218\u001b[0m     (\n\u001b[1;32m   4219\u001b[0m         model,\n\u001b[1;32m   4220\u001b[0m         missing_keys,\n\u001b[1;32m   4221\u001b[0m         unexpected_keys,\n\u001b[1;32m   4222\u001b[0m         mismatched_keys,\n\u001b[1;32m   4223\u001b[0m         offload_index,\n\u001b[1;32m   4224\u001b[0m         error_msgs,\n\u001b[0;32m-> 4225\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_pretrained_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4226\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4227\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4228\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloaded_state_dict_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# XXX: rename?\u001b[39;49;00m\n\u001b[1;32m   4229\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresolved_archive_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4230\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4231\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4232\u001b[0m \u001b[43m        \u001b[49m\u001b[43msharded_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msharded_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4233\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_fast_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_fast_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4234\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlow_cpu_mem_usage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlow_cpu_mem_usage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4235\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4236\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4237\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload_state_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_state_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4238\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4239\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4240\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4241\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgguf_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgguf_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4242\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweights_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4243\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4245\u001b[0m \u001b[38;5;66;03m# make sure token embedding weights are still tied if needed\u001b[39;00m\n\u001b[1;32m   4246\u001b[0m model\u001b[38;5;241m.\u001b[39mtie_weights()\n",
      "File \u001b[0;32m~/Documents/Large-Language-Models/Assignments/LLM-PSU-Assignment-2/.venv/lib/python3.12/site-packages/transformers/modeling_utils.py:4751\u001b[0m, in \u001b[0;36mPreTrainedModel._load_pretrained_model\u001b[0;34m(cls, model, state_dict, loaded_keys, resolved_archive_file, pretrained_model_name_or_path, ignore_mismatched_sizes, sharded_metadata, _fast_init, low_cpu_mem_usage, device_map, offload_folder, offload_state_dict, dtype, hf_quantizer, keep_in_fp32_modules, gguf_path, weights_only)\u001b[0m\n\u001b[1;32m   4747\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m assign_to_params_buffers \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   4748\u001b[0m         assign_to_params_buffers \u001b[38;5;241m=\u001b[39m check_support_param_buffer_assignment(\n\u001b[1;32m   4749\u001b[0m             model_to_load, state_dict, start_prefix\n\u001b[1;32m   4750\u001b[0m         )\n\u001b[0;32m-> 4751\u001b[0m     error_msgs \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43m_load_state_dict_into_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4752\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_to_load\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_prefix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43massign_to_params_buffers\u001b[49m\n\u001b[1;32m   4753\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4755\u001b[0m \u001b[38;5;66;03m# force memory release\u001b[39;00m\n\u001b[1;32m   4756\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m state_dict\n",
      "File \u001b[0;32m~/Documents/Large-Language-Models/Assignments/LLM-PSU-Assignment-2/.venv/lib/python3.12/site-packages/transformers/modeling_utils.py:775\u001b[0m, in \u001b[0;36m_load_state_dict_into_model\u001b[0;34m(model_to_load, state_dict, start_prefix, assign_to_params_buffers)\u001b[0m\n\u001b[1;32m    772\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m child \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    773\u001b[0m             load(child, state_dict, prefix \u001b[38;5;241m+\u001b[39m name \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, assign_to_params_buffers)\n\u001b[0;32m--> 775\u001b[0m \u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_to_load\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_prefix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43massign_to_params_buffers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43massign_to_params_buffers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    776\u001b[0m \u001b[38;5;66;03m# Delete `state_dict` so it could be collected by GC earlier. Note that `state_dict` is a copy of the argument, so\u001b[39;00m\n\u001b[1;32m    777\u001b[0m \u001b[38;5;66;03m# it's safe to delete it.\u001b[39;00m\n\u001b[1;32m    778\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m state_dict\n",
      "File \u001b[0;32m~/Documents/Large-Language-Models/Assignments/LLM-PSU-Assignment-2/.venv/lib/python3.12/site-packages/transformers/modeling_utils.py:773\u001b[0m, in \u001b[0;36m_load_state_dict_into_model.<locals>.load\u001b[0;34m(module, state_dict, prefix, assign_to_params_buffers)\u001b[0m\n\u001b[1;32m    771\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, child \u001b[38;5;129;01min\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_modules\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    772\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m child \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 773\u001b[0m         \u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchild\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43massign_to_params_buffers\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Large-Language-Models/Assignments/LLM-PSU-Assignment-2/.venv/lib/python3.12/site-packages/transformers/modeling_utils.py:773\u001b[0m, in \u001b[0;36m_load_state_dict_into_model.<locals>.load\u001b[0;34m(module, state_dict, prefix, assign_to_params_buffers)\u001b[0m\n\u001b[1;32m    771\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, child \u001b[38;5;129;01min\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_modules\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    772\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m child \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 773\u001b[0m         \u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchild\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43massign_to_params_buffers\u001b[49m\u001b[43m)\u001b[49m\n",
      "    \u001b[0;31m[... skipping similar frames: _load_state_dict_into_model.<locals>.load at line 773 (2 times)]\u001b[0m\n",
      "File \u001b[0;32m~/Documents/Large-Language-Models/Assignments/LLM-PSU-Assignment-2/.venv/lib/python3.12/site-packages/transformers/modeling_utils.py:773\u001b[0m, in \u001b[0;36m_load_state_dict_into_model.<locals>.load\u001b[0;34m(module, state_dict, prefix, assign_to_params_buffers)\u001b[0m\n\u001b[1;32m    771\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, child \u001b[38;5;129;01min\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_modules\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    772\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m child \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 773\u001b[0m         \u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchild\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43massign_to_params_buffers\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Large-Language-Models/Assignments/LLM-PSU-Assignment-2/.venv/lib/python3.12/site-packages/transformers/modeling_utils.py:769\u001b[0m, in \u001b[0;36m_load_state_dict_into_model.<locals>.load\u001b[0;34m(module, state_dict, prefix, assign_to_params_buffers)\u001b[0m\n\u001b[1;32m    767\u001b[0m                     module\u001b[38;5;241m.\u001b[39m_load_from_state_dict(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m    768\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 769\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_from_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    771\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, child \u001b[38;5;129;01min\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_modules\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    772\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m child \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Documents/Large-Language-Models/Assignments/LLM-PSU-Assignment-2/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:2441\u001b[0m, in \u001b[0;36mModule._load_from_state_dict\u001b[0;34m(self, state_dict, prefix, local_metadata, strict, missing_keys, unexpected_keys, error_msgs)\u001b[0m\n\u001b[1;32m   2439\u001b[0m             \u001b[38;5;28msetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, input_param)\n\u001b[1;32m   2440\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2441\u001b[0m             \u001b[43mparam\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy_\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_param\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2442\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[1;32m   2443\u001b[0m     action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mswapping\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m use_swap_tensors \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcopying\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "# model name\n",
    "phi_model = \"microsoft/Phi-3.5-mini-instruct\"\n",
    "\n",
    "phi_3_5_tokenizer = AutoTokenizer.from_pretrained(phi_model)\n",
    "\n",
    "phi_3_5_model = AutoModelForCausalLM.from_pretrained(phi_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1518e687",
   "metadata": {},
   "source": [
    "## Experiments 1: Zero-Shot Inference "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9562780e-68e0-43ff-a06a-72ce676a2f30",
   "metadata": {},
   "source": [
    "### Create Prompt Iteration Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "973c79d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\\\"{}\\\" \\n Sentiment (positive (2), negative (0), neutral (1)): \""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50d681b",
   "metadata": {},
   "source": [
    "### Llama 3.3 1B: Zero Shot Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed8764fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31587\n",
      "43324\n",
      "60668\n"
     ]
    }
   ],
   "source": [
    "# encode possible labels \n",
    "positive_id = llama_3_2_1B_tokenizer.encode(\"positive\", add_special_tokens=False)[0]\n",
    "negative_id = llama_3_2_1B_tokenizer.encode(\"negative\", add_special_tokens=False)[0]\n",
    "neutral_id = llama_3_2_1B_tokenizer.encode(\"neutral\", add_special_tokens=False)[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "6aaae4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def sanitize_tweet(tweet):\n",
    "    sanitized_tweet = re.sub(r\"(\\@\\w+ | \\#\\w+)\",\"\", tweet)\n",
    "    return sanitized_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "360ce730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I think after Charlie Hebdo the French did NOT react as the US did after 9/11. But they may do this time around. \n",
      "Beautiful Bouquet with our Beautiful Bentley  ...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# sanitize tweets\n",
    "# removes user tags\n",
    "tweet_user = \"@user @user I think after Charlie Hebdo the French did NOT react as the US did after 9/11. But they may do this time around. \"\n",
    "\n",
    "user_swap = re.sub(r'\\@\\w+',\"\", tweet_user)\n",
    "\n",
    "sanitize_tweet(tweet_user)\n",
    "\n",
    "# hash tag heavy tweet\n",
    "hash_tag_tweet = \"Beautiful Bouquet with our Beautiful Bentley #bride #groom #wedding #wednesday #weddingcars #love   #Repost...\"\n",
    "\n",
    "tag_swap = re.sub(r'\\#\\w+',\"\", hash_tag_tweet)\n",
    "\n",
    "sanitize_tweet(hash_tag_tweet)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85d7826-d069-4903-8b37-19a081a4d2a2",
   "metadata": {},
   "source": [
    "### Approach 1: Parse Single Token Response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbccdd1e-433d-4e28-8d14-a9fc92a15ff3",
   "metadata": {},
   "source": [
    "This approach prompts the model in question for a sentiment classification of a tweet, the **[AutoModelForCausalLM's](https://huggingface.co/docs/transformers/v4.46.0/en/main_classes/text_generation#transformers.GenerationMixin.generate)** `mode.generate()` call is invoked in order to ellicit a response to our provided prompt. the `generate()` method can be provided with several parameters. this approach modifies the **[GenerationConfiguration](https://huggingface.co/docs/transformers/v4.46.0/en/main_classes/text_generation#transformers.GenerationConfig)** allowing for certain constraints. for this approach we ensure that the `max_new_tokens=1` and `pad_token_id` is set to ensure there is only one token generated from the model. This token is then used to represent our model's response to the sentiment prompt. \n",
    "\n",
    "This approach can work but there are risks associated with this method, because these models haven't gone through any **fine-tuning**. Meaning their lack of training hasn't prepared them to for **sentiment classification**, meaning instead of receiving a \"0\" for neutral, \"1\" for negative, or \"2\" for positive there could be other undesirable tokens coming back. To handle this I created a `santize_response()` method that will take the generated tokens and determine if the response can be related to a sentiment classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c8d3bc8e-5452-48a5-a7d6-d9c7a8e4d32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def santize_response(response_token):\n",
    "    if re.search(r'\\d', response_token):\n",
    "        return int(response_token)\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "61a057d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# hold the ground_truths\n",
    "ground_truths = []\n",
    "# hold the sentiment_predictions\n",
    "sentiment_preds = []\n",
    "\n",
    "# iterate through the validation set\n",
    "for tweet, label in zip(ds_validation['text'], ds_validation['label']):\n",
    "    prompt_tweet = tweet\n",
    "    gt_label = label\n",
    "    # combine the prompt\n",
    "    prompt = prompt_template.format(prompt_tweet)\n",
    "    \n",
    "    # generate the response\n",
    "    prompt_ids = llama_3_2_1B_tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "\n",
    "    outputs = llama_3_2_1B_model.generate(\n",
    "                        prompt_ids,\n",
    "                        pad_token_id=llama_3_2_1B_tokenizer.eos_token_id,\n",
    "                        max_new_tokens=1\n",
    "                    )\n",
    "    \n",
    "    # get the response tokens from the model\n",
    "    generated_tokens = outputs[-1]\n",
    "    \n",
    "    generated_response = llama_3_2_1B_tokenizer.decode(generated_tokens, skip_special_tokens=True)\n",
    "\n",
    "    # pass the generated_response to a sanitizer that determines if the response is valid\n",
    "    sentiment_resp = santize_response(generated_response[-1])\n",
    "    \n",
    "    # Responses being compared to the Ground_Truth Labels\n",
    "    # print(f\"Generated Response: {sentiment_resp}\")\n",
    "    # print(f\"Ground Truth: {gt_label}\")\n",
    "\n",
    "    ground_truths.append(gt_label)\n",
    "    sentiment_preds.append(sentiment_resp)\n",
    "\n",
    "ground_truths = np.asarray(ground_truths)\n",
    "sentiment_preds = np.asarray(sentiment_preds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdeaff9e",
   "metadata": {},
   "source": [
    "### Build Classification Report "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ddda6d9",
   "metadata": {},
   "source": [
    "**Import Python Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c1609a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install scikit-learn matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "896b68f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.61      0.49       108\n",
      "           1       0.43      0.31      0.36       108\n",
      "           2       0.39      0.31      0.34       108\n",
      "\n",
      "    accuracy                           0.41       324\n",
      "   macro avg       0.41      0.41      0.40       324\n",
      "weighted avg       0.41      0.41      0.40       324\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(ground_truths, sentiment_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b40b3d6",
   "metadata": {},
   "source": [
    "### Build Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "df3f3c11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "\n",
    "cm = confusion_matrix(ground_truths, sentiment_preds)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1414fc3b",
   "metadata": {},
   "source": [
    "### Approach 2: Use Logits to Determine Text Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "af668c42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'positive': 31587, 'negative': 43324, 'neutral': 60668}\n"
     ]
    }
   ],
   "source": [
    "sentiment_ids = {}\n",
    "# encode possible labels \n",
    "sentiment_ids[\"positive\"] = llama_3_2_1B_tokenizer.encode(\"positive\", add_special_tokens=False)[0]\n",
    "sentiment_ids[\"negative\"] = llama_3_2_1B_tokenizer.encode(\"negative\", add_special_tokens=False)[0]\n",
    "sentiment_ids[\"neutral\"] = llama_3_2_1B_tokenizer.encode(\"neutral\", add_special_tokens=False)[0]\n",
    "\n",
    "print(sentiment_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "44be457a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment: positive\n",
      "Sentiment_ID: 31587\n",
      "Sentiment: negative\n",
      "Sentiment_ID: 43324\n",
      "Sentiment: neutral\n",
      "Sentiment_ID: 60668\n"
     ]
    }
   ],
   "source": [
    "for sentiment in sentiment_ids:\n",
    "    print(f\"Sentiment: {sentiment}\")\n",
    "    print(f\"Sentiment_ID: {sentiment_ids[sentiment]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44956bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # iterate through the validation set\n",
    "for tweet, label in zip(ds_validation['text'], ds_validation['label']):\n",
    "    prompt_tweet = sanitize_tweet(tweet=tweet)\n",
    "    print(f\"Prompt_tweet: {prompt_tweet}\")\n",
    "    gt_label = label\n",
    "    # combine the prompt\n",
    "    prompt = prompt_template.format(prompt_tweet)\n",
    "    \n",
    "    prompt_ids = llama_3_2_1B_tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = llama_3_2_1B_model(prompt_ids)\n",
    "    \n",
    "        # get the output logits\n",
    "        logits = outputs.logits\n",
    "\n",
    "    \n",
    "    log_probs = torch.nn.functional.log_softmax(logits, dim=-1)\n",
    "\n",
    "    # build a list of the sentiment options and the probability per sentiment\n",
    "    tweet_sentiment_probabilities = {}\n",
    "\n",
    "    for sentiment in sentiment_ids:\n",
    "        tweet_sentiment_probabilities[sentiment] = log_probs[0, -1, sentiment_ids[sentiment]].item()\n",
    "    \n",
    "    \n",
    "    max_sentiment = max(tweet_sentiment_probabilities, key=tweet_sentiment_probabilities.get)\n",
    "    print(tweet_sentiment_probabilities)\n",
    "    print(max_sentiment)\n",
    "    \n",
    "    print(\"-----------------------------\")\n",
    "    print(f\"Tweet Prompt: {prompt}\")\n",
    "    print(f\"Ground Truth: {gt_label}\")\n",
    "    print(f\"Predicted Sentiment: {max_sentiment}\")\n",
    "    print(\"-----------------------------\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
